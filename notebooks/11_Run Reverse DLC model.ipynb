{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fafdcb86",
   "metadata": {},
   "source": [
    "#### This notebook is for ruunig the reverse model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f9b9d25",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "import movement_classifier.utils as utils\n",
    "import movement_classifier.data_loader as data_loader\n",
    "import movement_classifier.model_funcs as model_funcs\n",
    "import movement_classifier.gpt_reverse_model as gpt_reverse_model\n",
    "\n",
    "from os.path import dirname, join as pjoin\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import dlc2kinematics\n",
    "from scipy.interpolate import CubicSpline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "from celluloid import Camera\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import torch\n",
    "import plotly\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d25390d",
   "metadata": {
    "lines_to_end_of_cell_marker": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Step [2/9], Loss: 29.9627, Accuracy: 3.00%\n",
      "Epoch [1/200], Step [4/9], Loss: 6.8602, Accuracy: 14.00%\n",
      "Epoch [1/200], Step [6/9], Loss: 5.2315, Accuracy: 16.00%\n",
      "Epoch [1/200], Step [8/9], Loss: 5.2639, Accuracy: 5.00%\n",
      "Epoch [2/200], Step [2/9], Loss: 5.1624, Accuracy: 15.00%\n",
      "Epoch [2/200], Step [4/9], Loss: 5.0865, Accuracy: 15.00%\n",
      "Epoch [2/200], Step [6/9], Loss: 5.0790, Accuracy: 14.00%\n",
      "Epoch [2/200], Step [8/9], Loss: 4.9873, Accuracy: 21.00%\n",
      "Epoch [3/200], Step [2/9], Loss: 4.9088, Accuracy: 30.00%\n",
      "Epoch [3/200], Step [4/9], Loss: 4.9189, Accuracy: 25.00%\n",
      "Epoch [3/200], Step [6/9], Loss: 4.9338, Accuracy: 26.00%\n",
      "Epoch [3/200], Step [8/9], Loss: 4.8854, Accuracy: 33.00%\n",
      "Epoch [4/200], Step [2/9], Loss: 4.7598, Accuracy: 40.00%\n",
      "Epoch [4/200], Step [4/9], Loss: 4.8610, Accuracy: 17.00%\n",
      "Epoch [4/200], Step [6/9], Loss: 4.7476, Accuracy: 27.00%\n",
      "Epoch [4/200], Step [8/9], Loss: 4.7021, Accuracy: 37.00%\n",
      "Epoch [5/200], Step [2/9], Loss: 4.5521, Accuracy: 33.00%\n",
      "Epoch [5/200], Step [4/9], Loss: 4.6541, Accuracy: 28.00%\n",
      "Epoch [5/200], Step [6/9], Loss: 4.6788, Accuracy: 35.00%\n",
      "Epoch [5/200], Step [8/9], Loss: 4.5844, Accuracy: 31.00%\n",
      "Epoch [6/200], Step [2/9], Loss: 4.3144, Accuracy: 43.00%\n",
      "Epoch [6/200], Step [4/9], Loss: 4.3434, Accuracy: 47.00%\n",
      "Epoch [6/200], Step [6/9], Loss: 4.4519, Accuracy: 40.00%\n",
      "Epoch [6/200], Step [8/9], Loss: 4.3330, Accuracy: 40.00%\n",
      "Epoch [7/200], Step [2/9], Loss: 4.2418, Accuracy: 49.00%\n",
      "Epoch [7/200], Step [4/9], Loss: 4.3577, Accuracy: 38.00%\n",
      "Epoch [7/200], Step [6/9], Loss: 4.2790, Accuracy: 41.00%\n",
      "Epoch [7/200], Step [8/9], Loss: 4.1703, Accuracy: 68.00%\n",
      "Epoch [8/200], Step [2/9], Loss: 4.2347, Accuracy: 46.00%\n",
      "Epoch [8/200], Step [4/9], Loss: 4.0426, Accuracy: 65.00%\n",
      "Epoch [8/200], Step [6/9], Loss: 4.2084, Accuracy: 48.00%\n",
      "Epoch [8/200], Step [8/9], Loss: 3.9291, Accuracy: 61.00%\n",
      "Epoch [9/200], Step [2/9], Loss: 3.9280, Accuracy: 66.00%\n",
      "Epoch [9/200], Step [4/9], Loss: 3.9711, Accuracy: 54.00%\n",
      "Epoch [9/200], Step [6/9], Loss: 3.8432, Accuracy: 71.00%\n",
      "Epoch [9/200], Step [8/9], Loss: 3.9946, Accuracy: 59.00%\n",
      "Epoch [10/200], Step [2/9], Loss: 3.9168, Accuracy: 59.00%\n",
      "Epoch [10/200], Step [4/9], Loss: 3.7766, Accuracy: 69.00%\n",
      "Epoch [10/200], Step [6/9], Loss: 3.8871, Accuracy: 61.00%\n",
      "Epoch [10/200], Step [8/9], Loss: 3.7421, Accuracy: 61.00%\n",
      "Epoch [11/200], Step [2/9], Loss: 3.7041, Accuracy: 69.00%\n",
      "Epoch [11/200], Step [4/9], Loss: 3.6288, Accuracy: 66.00%\n",
      "Epoch [11/200], Step [6/9], Loss: 3.5840, Accuracy: 76.00%\n",
      "Epoch [11/200], Step [8/9], Loss: 3.7733, Accuracy: 61.00%\n",
      "Epoch [12/200], Step [2/9], Loss: 3.5692, Accuracy: 70.00%\n",
      "Epoch [12/200], Step [4/9], Loss: 3.6739, Accuracy: 71.00%\n",
      "Epoch [12/200], Step [6/9], Loss: 3.5964, Accuracy: 74.00%\n",
      "Epoch [12/200], Step [8/9], Loss: 3.6919, Accuracy: 67.00%\n",
      "Epoch [13/200], Step [2/9], Loss: 3.5752, Accuracy: 72.00%\n",
      "Epoch [13/200], Step [4/9], Loss: 3.5963, Accuracy: 74.00%\n",
      "Epoch [13/200], Step [6/9], Loss: 3.6718, Accuracy: 66.00%\n",
      "Epoch [13/200], Step [8/9], Loss: 3.6211, Accuracy: 69.00%\n",
      "Epoch [14/200], Step [2/9], Loss: 3.5118, Accuracy: 77.00%\n",
      "Epoch [14/200], Step [4/9], Loss: 3.5197, Accuracy: 72.00%\n",
      "Epoch [14/200], Step [6/9], Loss: 3.6997, Accuracy: 67.00%\n",
      "Epoch [14/200], Step [8/9], Loss: 3.4936, Accuracy: 73.00%\n",
      "Epoch [15/200], Step [2/9], Loss: 3.4671, Accuracy: 78.00%\n",
      "Epoch [15/200], Step [4/9], Loss: 3.4588, Accuracy: 81.00%\n",
      "Epoch [15/200], Step [6/9], Loss: 3.5900, Accuracy: 69.00%\n",
      "Epoch [15/200], Step [8/9], Loss: 3.5671, Accuracy: 75.00%\n",
      "Epoch [16/200], Step [2/9], Loss: 3.3607, Accuracy: 82.00%\n",
      "Epoch [16/200], Step [4/9], Loss: 3.6393, Accuracy: 71.00%\n",
      "Epoch [16/200], Step [6/9], Loss: 3.3758, Accuracy: 79.00%\n",
      "Epoch [16/200], Step [8/9], Loss: 3.5760, Accuracy: 68.00%\n",
      "Epoch [17/200], Step [2/9], Loss: 3.4105, Accuracy: 74.00%\n",
      "Epoch [17/200], Step [4/9], Loss: 3.4821, Accuracy: 71.00%\n",
      "Epoch [17/200], Step [6/9], Loss: 3.4191, Accuracy: 78.00%\n",
      "Epoch [17/200], Step [8/9], Loss: 3.3971, Accuracy: 77.00%\n",
      "Epoch [18/200], Step [2/9], Loss: 3.4399, Accuracy: 77.00%\n",
      "Epoch [18/200], Step [4/9], Loss: 3.3279, Accuracy: 84.00%\n",
      "Epoch [18/200], Step [6/9], Loss: 3.3042, Accuracy: 82.00%\n",
      "Epoch [18/200], Step [8/9], Loss: 3.3778, Accuracy: 76.00%\n",
      "Epoch [19/200], Step [2/9], Loss: 3.2768, Accuracy: 84.00%\n",
      "Epoch [19/200], Step [4/9], Loss: 3.3712, Accuracy: 75.00%\n",
      "Epoch [19/200], Step [6/9], Loss: 3.2384, Accuracy: 84.00%\n",
      "Epoch [19/200], Step [8/9], Loss: 3.3305, Accuracy: 75.00%\n",
      "Epoch [20/200], Step [2/9], Loss: 3.2812, Accuracy: 82.00%\n",
      "Epoch [20/200], Step [4/9], Loss: 3.3092, Accuracy: 84.00%\n",
      "Epoch [20/200], Step [6/9], Loss: 3.5390, Accuracy: 73.00%\n",
      "Epoch [20/200], Step [8/9], Loss: 3.3509, Accuracy: 77.00%\n",
      "Epoch [21/200], Step [2/9], Loss: 3.3759, Accuracy: 69.00%\n",
      "Epoch [21/200], Step [4/9], Loss: 3.2931, Accuracy: 83.00%\n",
      "Epoch [21/200], Step [6/9], Loss: 3.3219, Accuracy: 78.00%\n",
      "Epoch [21/200], Step [8/9], Loss: 3.2737, Accuracy: 82.00%\n",
      "Epoch [22/200], Step [2/9], Loss: 3.2826, Accuracy: 85.00%\n",
      "Epoch [22/200], Step [4/9], Loss: 3.1810, Accuracy: 84.00%\n",
      "Epoch [22/200], Step [6/9], Loss: 3.2321, Accuracy: 85.00%\n",
      "Epoch [22/200], Step [8/9], Loss: 3.2599, Accuracy: 78.00%\n",
      "Epoch [23/200], Step [2/9], Loss: 3.2303, Accuracy: 83.00%\n",
      "Epoch [23/200], Step [4/9], Loss: 3.3420, Accuracy: 77.00%\n",
      "Epoch [23/200], Step [6/9], Loss: 3.2893, Accuracy: 82.00%\n",
      "Epoch [23/200], Step [8/9], Loss: 3.4704, Accuracy: 68.00%\n",
      "Epoch [24/200], Step [2/9], Loss: 3.4999, Accuracy: 70.00%\n",
      "Epoch [24/200], Step [4/9], Loss: 3.3600, Accuracy: 82.00%\n",
      "Epoch [24/200], Step [6/9], Loss: 3.3314, Accuracy: 72.00%\n",
      "Epoch [24/200], Step [8/9], Loss: 3.4411, Accuracy: 72.00%\n",
      "Epoch [25/200], Step [2/9], Loss: 3.3986, Accuracy: 77.00%\n",
      "Epoch [25/200], Step [4/9], Loss: 3.2388, Accuracy: 81.00%\n",
      "Epoch [25/200], Step [6/9], Loss: 3.1528, Accuracy: 86.00%\n",
      "Epoch [25/200], Step [8/9], Loss: 3.2243, Accuracy: 80.00%\n",
      "Epoch [26/200], Step [2/9], Loss: 3.0946, Accuracy: 87.00%\n",
      "Epoch [26/200], Step [4/9], Loss: 3.0302, Accuracy: 91.00%\n",
      "Epoch [26/200], Step [6/9], Loss: 3.1803, Accuracy: 82.00%\n",
      "Epoch [26/200], Step [8/9], Loss: 3.1027, Accuracy: 85.00%\n",
      "Epoch [27/200], Step [2/9], Loss: 3.1161, Accuracy: 84.00%\n",
      "Epoch [27/200], Step [4/9], Loss: 3.0931, Accuracy: 87.00%\n",
      "Epoch [27/200], Step [6/9], Loss: 3.0885, Accuracy: 90.00%\n",
      "Epoch [27/200], Step [8/9], Loss: 3.1098, Accuracy: 88.00%\n",
      "Epoch [28/200], Step [2/9], Loss: 3.0904, Accuracy: 88.00%\n",
      "Epoch [28/200], Step [4/9], Loss: 3.1070, Accuracy: 87.00%\n",
      "Epoch [28/200], Step [6/9], Loss: 3.0753, Accuracy: 89.00%\n",
      "Epoch [28/200], Step [8/9], Loss: 3.0562, Accuracy: 86.00%\n",
      "Epoch [29/200], Step [2/9], Loss: 3.1672, Accuracy: 86.00%\n",
      "Epoch [29/200], Step [4/9], Loss: 3.0410, Accuracy: 92.00%\n",
      "Epoch [29/200], Step [6/9], Loss: 3.0663, Accuracy: 92.00%\n",
      "Epoch [29/200], Step [8/9], Loss: 3.1015, Accuracy: 83.00%\n",
      "Epoch [30/200], Step [2/9], Loss: 2.9920, Accuracy: 91.00%\n",
      "Epoch [30/200], Step [4/9], Loss: 3.0892, Accuracy: 86.00%\n",
      "Epoch [30/200], Step [6/9], Loss: 3.0532, Accuracy: 88.00%\n",
      "Epoch [30/200], Step [8/9], Loss: 3.0954, Accuracy: 86.00%\n",
      "Epoch [31/200], Step [2/9], Loss: 3.0598, Accuracy: 87.00%\n",
      "Epoch [31/200], Step [4/9], Loss: 2.9507, Accuracy: 95.00%\n",
      "Epoch [31/200], Step [6/9], Loss: 2.9825, Accuracy: 93.00%\n",
      "Epoch [31/200], Step [8/9], Loss: 3.0025, Accuracy: 91.00%\n",
      "Epoch [32/200], Step [2/9], Loss: 2.9960, Accuracy: 88.00%\n",
      "Epoch [32/200], Step [4/9], Loss: 3.0496, Accuracy: 87.00%\n",
      "Epoch [32/200], Step [6/9], Loss: 2.9698, Accuracy: 92.00%\n",
      "Epoch [32/200], Step [8/9], Loss: 3.0975, Accuracy: 87.00%\n",
      "Epoch [33/200], Step [2/9], Loss: 3.1740, Accuracy: 81.00%\n",
      "Epoch [33/200], Step [4/9], Loss: 3.0995, Accuracy: 87.00%\n",
      "Epoch [33/200], Step [6/9], Loss: 3.0152, Accuracy: 89.00%\n",
      "Epoch [33/200], Step [8/9], Loss: 3.1648, Accuracy: 83.00%\n",
      "Epoch [34/200], Step [2/9], Loss: 2.9701, Accuracy: 91.00%\n",
      "Epoch [34/200], Step [4/9], Loss: 3.0224, Accuracy: 86.00%\n",
      "Epoch [34/200], Step [6/9], Loss: 3.0738, Accuracy: 90.00%\n",
      "Epoch [34/200], Step [8/9], Loss: 2.9271, Accuracy: 93.00%\n",
      "Epoch [35/200], Step [2/9], Loss: 3.0586, Accuracy: 85.00%\n",
      "Epoch [35/200], Step [4/9], Loss: 3.0009, Accuracy: 93.00%\n",
      "Epoch [35/200], Step [6/9], Loss: 2.9576, Accuracy: 91.00%\n",
      "Epoch [35/200], Step [8/9], Loss: 2.9371, Accuracy: 93.00%\n",
      "Epoch [36/200], Step [2/9], Loss: 2.9859, Accuracy: 87.00%\n",
      "Epoch [36/200], Step [4/9], Loss: 2.9100, Accuracy: 91.00%\n",
      "Epoch [36/200], Step [6/9], Loss: 3.0041, Accuracy: 90.00%\n",
      "Epoch [36/200], Step [8/9], Loss: 2.9769, Accuracy: 90.00%\n",
      "Epoch [37/200], Step [2/9], Loss: 2.9084, Accuracy: 91.00%\n",
      "Epoch [37/200], Step [4/9], Loss: 2.9894, Accuracy: 91.00%\n",
      "Epoch [37/200], Step [6/9], Loss: 2.8913, Accuracy: 93.00%\n",
      "Epoch [37/200], Step [8/9], Loss: 2.9328, Accuracy: 92.00%\n",
      "Epoch [38/200], Step [2/9], Loss: 2.9053, Accuracy: 93.00%\n",
      "Epoch [38/200], Step [4/9], Loss: 2.8486, Accuracy: 94.00%\n",
      "Epoch [38/200], Step [6/9], Loss: 2.9012, Accuracy: 94.00%\n",
      "Epoch [38/200], Step [8/9], Loss: 2.8684, Accuracy: 95.00%\n",
      "Epoch [39/200], Step [2/9], Loss: 2.9021, Accuracy: 96.00%\n",
      "Epoch [39/200], Step [4/9], Loss: 2.9608, Accuracy: 90.00%\n",
      "Epoch [39/200], Step [6/9], Loss: 2.9170, Accuracy: 93.00%\n",
      "Epoch [39/200], Step [8/9], Loss: 2.9265, Accuracy: 91.00%\n",
      "Epoch [40/200], Step [2/9], Loss: 2.8800, Accuracy: 98.00%\n",
      "Epoch [40/200], Step [4/9], Loss: 2.8830, Accuracy: 93.00%\n",
      "Epoch [40/200], Step [6/9], Loss: 2.8753, Accuracy: 92.00%\n",
      "Epoch [40/200], Step [8/9], Loss: 2.9208, Accuracy: 91.00%\n",
      "Epoch [41/200], Step [2/9], Loss: 2.8108, Accuracy: 100.00%\n",
      "Epoch [41/200], Step [4/9], Loss: 2.9424, Accuracy: 92.00%\n",
      "Epoch [41/200], Step [6/9], Loss: 2.9213, Accuracy: 91.00%\n",
      "Epoch [41/200], Step [8/9], Loss: 2.9302, Accuracy: 91.00%\n",
      "Epoch [42/200], Step [2/9], Loss: 2.8825, Accuracy: 94.00%\n",
      "Epoch [42/200], Step [4/9], Loss: 2.8752, Accuracy: 93.00%\n",
      "Epoch [42/200], Step [6/9], Loss: 3.0115, Accuracy: 89.00%\n",
      "Epoch [42/200], Step [8/9], Loss: 2.9122, Accuracy: 92.00%\n",
      "Epoch [43/200], Step [2/9], Loss: 2.9080, Accuracy: 94.00%\n",
      "Epoch [43/200], Step [4/9], Loss: 2.9009, Accuracy: 96.00%\n",
      "Epoch [43/200], Step [6/9], Loss: 2.8062, Accuracy: 96.00%\n",
      "Epoch [43/200], Step [8/9], Loss: 2.8605, Accuracy: 93.00%\n",
      "Epoch [44/200], Step [2/9], Loss: 2.8601, Accuracy: 93.00%\n",
      "Epoch [44/200], Step [4/9], Loss: 2.8456, Accuracy: 94.00%\n",
      "Epoch [44/200], Step [6/9], Loss: 2.9307, Accuracy: 90.00%\n",
      "Epoch [44/200], Step [8/9], Loss: 2.8030, Accuracy: 98.00%\n",
      "Epoch [45/200], Step [2/9], Loss: 2.8658, Accuracy: 94.00%\n",
      "Epoch [45/200], Step [4/9], Loss: 2.7986, Accuracy: 97.00%\n",
      "Epoch [45/200], Step [6/9], Loss: 2.8439, Accuracy: 96.00%\n",
      "Epoch [45/200], Step [8/9], Loss: 2.8545, Accuracy: 92.00%\n",
      "Epoch [46/200], Step [2/9], Loss: 2.8913, Accuracy: 94.00%\n",
      "Epoch [46/200], Step [4/9], Loss: 2.8316, Accuracy: 94.00%\n",
      "Epoch [46/200], Step [6/9], Loss: 2.8294, Accuracy: 95.00%\n",
      "Epoch [46/200], Step [8/9], Loss: 2.8836, Accuracy: 90.00%\n",
      "Epoch [47/200], Step [2/9], Loss: 2.8014, Accuracy: 94.00%\n",
      "Epoch [47/200], Step [4/9], Loss: 2.8341, Accuracy: 96.00%\n",
      "Epoch [47/200], Step [6/9], Loss: 2.7961, Accuracy: 98.00%\n",
      "Epoch [47/200], Step [8/9], Loss: 2.8861, Accuracy: 94.00%\n",
      "Epoch [48/200], Step [2/9], Loss: 2.8244, Accuracy: 95.00%\n",
      "Epoch [48/200], Step [4/9], Loss: 2.8216, Accuracy: 94.00%\n",
      "Epoch [48/200], Step [6/9], Loss: 2.8960, Accuracy: 91.00%\n",
      "Epoch [48/200], Step [8/9], Loss: 2.8770, Accuracy: 94.00%\n",
      "Epoch [49/200], Step [2/9], Loss: 2.8447, Accuracy: 96.00%\n",
      "Epoch [49/200], Step [4/9], Loss: 2.8296, Accuracy: 93.00%\n",
      "Epoch [49/200], Step [6/9], Loss: 2.9311, Accuracy: 89.00%\n",
      "Epoch [49/200], Step [8/9], Loss: 2.8528, Accuracy: 93.00%\n",
      "Epoch [50/200], Step [2/9], Loss: 2.8371, Accuracy: 89.00%\n",
      "Epoch [50/200], Step [4/9], Loss: 2.8003, Accuracy: 94.00%\n",
      "Epoch [50/200], Step [6/9], Loss: 2.8066, Accuracy: 93.00%\n",
      "Epoch [50/200], Step [8/9], Loss: 2.8015, Accuracy: 95.00%\n",
      "Epoch [51/200], Step [2/9], Loss: 2.8810, Accuracy: 93.00%\n",
      "Epoch [51/200], Step [4/9], Loss: 2.8291, Accuracy: 95.00%\n",
      "Epoch [51/200], Step [6/9], Loss: 2.8445, Accuracy: 91.00%\n",
      "Epoch [51/200], Step [8/9], Loss: 2.8519, Accuracy: 95.00%\n",
      "Epoch [52/200], Step [2/9], Loss: 2.7983, Accuracy: 94.00%\n",
      "Epoch [52/200], Step [4/9], Loss: 2.8226, Accuracy: 97.00%\n",
      "Epoch [52/200], Step [6/9], Loss: 2.7880, Accuracy: 96.00%\n",
      "Epoch [52/200], Step [8/9], Loss: 2.8151, Accuracy: 95.00%\n",
      "Epoch [53/200], Step [2/9], Loss: 2.7524, Accuracy: 98.00%\n",
      "Epoch [53/200], Step [4/9], Loss: 2.8212, Accuracy: 96.00%\n",
      "Epoch [53/200], Step [6/9], Loss: 2.7812, Accuracy: 92.00%\n",
      "Epoch [53/200], Step [8/9], Loss: 2.7760, Accuracy: 95.00%\n",
      "Epoch [54/200], Step [2/9], Loss: 2.8108, Accuracy: 94.00%\n",
      "Epoch [54/200], Step [4/9], Loss: 2.8285, Accuracy: 93.00%\n",
      "Epoch [54/200], Step [6/9], Loss: 2.7582, Accuracy: 95.00%\n",
      "Epoch [54/200], Step [8/9], Loss: 2.8433, Accuracy: 95.00%\n",
      "Epoch [55/200], Step [2/9], Loss: 2.8499, Accuracy: 95.00%\n",
      "Epoch [55/200], Step [4/9], Loss: 2.7773, Accuracy: 97.00%\n",
      "Epoch [55/200], Step [6/9], Loss: 2.7971, Accuracy: 95.00%\n",
      "Epoch [55/200], Step [8/9], Loss: 2.7917, Accuracy: 95.00%\n",
      "Epoch [56/200], Step [2/9], Loss: 2.8639, Accuracy: 92.00%\n",
      "Epoch [56/200], Step [4/9], Loss: 2.7506, Accuracy: 97.00%\n",
      "Epoch [56/200], Step [6/9], Loss: 2.7900, Accuracy: 95.00%\n",
      "Epoch [56/200], Step [8/9], Loss: 2.6996, Accuracy: 100.00%\n",
      "Epoch [57/200], Step [2/9], Loss: 2.7985, Accuracy: 95.00%\n",
      "Epoch [57/200], Step [4/9], Loss: 2.7117, Accuracy: 99.00%\n",
      "Epoch [57/200], Step [6/9], Loss: 2.8239, Accuracy: 92.00%\n",
      "Epoch [57/200], Step [8/9], Loss: 2.7992, Accuracy: 96.00%\n",
      "Epoch [58/200], Step [2/9], Loss: 2.7767, Accuracy: 96.00%\n",
      "Epoch [58/200], Step [4/9], Loss: 2.7193, Accuracy: 98.00%\n",
      "Epoch [58/200], Step [6/9], Loss: 2.7707, Accuracy: 94.00%\n",
      "Epoch [58/200], Step [8/9], Loss: 2.7255, Accuracy: 96.00%\n",
      "Epoch [59/200], Step [2/9], Loss: 2.7523, Accuracy: 97.00%\n",
      "Epoch [59/200], Step [4/9], Loss: 2.7760, Accuracy: 95.00%\n",
      "Epoch [59/200], Step [6/9], Loss: 2.7660, Accuracy: 97.00%\n",
      "Epoch [59/200], Step [8/9], Loss: 2.8213, Accuracy: 94.00%\n",
      "Epoch [60/200], Step [2/9], Loss: 2.7737, Accuracy: 95.00%\n",
      "Epoch [60/200], Step [4/9], Loss: 2.7434, Accuracy: 96.00%\n",
      "Epoch [60/200], Step [6/9], Loss: 2.7301, Accuracy: 97.00%\n",
      "Epoch [60/200], Step [8/9], Loss: 2.7285, Accuracy: 96.00%\n",
      "Epoch [61/200], Step [2/9], Loss: 2.7719, Accuracy: 95.00%\n",
      "Epoch [61/200], Step [4/9], Loss: 2.8047, Accuracy: 93.00%\n",
      "Epoch [61/200], Step [6/9], Loss: 2.7049, Accuracy: 97.00%\n",
      "Epoch [61/200], Step [8/9], Loss: 2.7581, Accuracy: 96.00%\n",
      "Epoch [62/200], Step [2/9], Loss: 2.7130, Accuracy: 99.00%\n",
      "Epoch [62/200], Step [4/9], Loss: 2.7512, Accuracy: 95.00%\n",
      "Epoch [62/200], Step [6/9], Loss: 2.7368, Accuracy: 96.00%\n",
      "Epoch [62/200], Step [8/9], Loss: 2.7102, Accuracy: 97.00%\n",
      "Epoch [63/200], Step [2/9], Loss: 2.7158, Accuracy: 96.00%\n",
      "Epoch [63/200], Step [4/9], Loss: 2.7411, Accuracy: 96.00%\n",
      "Epoch [63/200], Step [6/9], Loss: 2.7537, Accuracy: 95.00%\n",
      "Epoch [63/200], Step [8/9], Loss: 2.6619, Accuracy: 98.00%\n",
      "Epoch [64/200], Step [2/9], Loss: 2.7187, Accuracy: 98.00%\n",
      "Epoch [64/200], Step [4/9], Loss: 2.6988, Accuracy: 96.00%\n",
      "Epoch [64/200], Step [6/9], Loss: 2.7193, Accuracy: 95.00%\n",
      "Epoch [64/200], Step [8/9], Loss: 2.7543, Accuracy: 98.00%\n",
      "Epoch [65/200], Step [2/9], Loss: 2.6799, Accuracy: 96.00%\n",
      "Epoch [65/200], Step [4/9], Loss: 2.6708, Accuracy: 98.00%\n",
      "Epoch [65/200], Step [6/9], Loss: 2.7309, Accuracy: 97.00%\n",
      "Epoch [65/200], Step [8/9], Loss: 2.7456, Accuracy: 94.00%\n",
      "Epoch [66/200], Step [2/9], Loss: 2.8062, Accuracy: 89.00%\n",
      "Epoch [66/200], Step [4/9], Loss: 2.7354, Accuracy: 97.00%\n",
      "Epoch [66/200], Step [6/9], Loss: 2.7130, Accuracy: 95.00%\n",
      "Epoch [66/200], Step [8/9], Loss: 2.7790, Accuracy: 95.00%\n",
      "Epoch [67/200], Step [2/9], Loss: 2.7431, Accuracy: 96.00%\n",
      "Epoch [67/200], Step [4/9], Loss: 2.6967, Accuracy: 96.00%\n",
      "Epoch [67/200], Step [6/9], Loss: 2.7869, Accuracy: 93.00%\n",
      "Epoch [67/200], Step [8/9], Loss: 2.7455, Accuracy: 96.00%\n",
      "Epoch [68/200], Step [2/9], Loss: 2.7309, Accuracy: 96.00%\n",
      "Epoch [68/200], Step [4/9], Loss: 2.7334, Accuracy: 96.00%\n",
      "Epoch [68/200], Step [6/9], Loss: 2.6909, Accuracy: 98.00%\n",
      "Epoch [68/200], Step [8/9], Loss: 2.8089, Accuracy: 94.00%\n",
      "Epoch [69/200], Step [2/9], Loss: 2.6770, Accuracy: 98.00%\n",
      "Epoch [69/200], Step [4/9], Loss: 2.7647, Accuracy: 95.00%\n",
      "Epoch [69/200], Step [6/9], Loss: 2.6792, Accuracy: 97.00%\n",
      "Epoch [69/200], Step [8/9], Loss: 2.7478, Accuracy: 94.00%\n",
      "Epoch [70/200], Step [2/9], Loss: 2.6992, Accuracy: 98.00%\n",
      "Epoch [70/200], Step [4/9], Loss: 2.7533, Accuracy: 91.00%\n",
      "Epoch [70/200], Step [6/9], Loss: 2.8208, Accuracy: 94.00%\n",
      "Epoch [70/200], Step [8/9], Loss: 2.6546, Accuracy: 100.00%\n",
      "Epoch [71/200], Step [2/9], Loss: 2.7511, Accuracy: 95.00%\n",
      "Epoch [71/200], Step [4/9], Loss: 2.6816, Accuracy: 97.00%\n",
      "Epoch [71/200], Step [6/9], Loss: 2.7764, Accuracy: 94.00%\n",
      "Epoch [71/200], Step [8/9], Loss: 2.6683, Accuracy: 97.00%\n",
      "Epoch [72/200], Step [2/9], Loss: 2.7547, Accuracy: 95.00%\n",
      "Epoch [72/200], Step [4/9], Loss: 2.6921, Accuracy: 98.00%\n",
      "Epoch [72/200], Step [6/9], Loss: 2.7309, Accuracy: 97.00%\n",
      "Epoch [72/200], Step [8/9], Loss: 2.6329, Accuracy: 99.00%\n",
      "Epoch [73/200], Step [2/9], Loss: 2.6835, Accuracy: 97.00%\n",
      "Epoch [73/200], Step [4/9], Loss: 2.7538, Accuracy: 93.00%\n",
      "Epoch [73/200], Step [6/9], Loss: 2.7292, Accuracy: 95.00%\n",
      "Epoch [73/200], Step [8/9], Loss: 2.7242, Accuracy: 96.00%\n",
      "Epoch [74/200], Step [2/9], Loss: 2.6864, Accuracy: 94.00%\n",
      "Epoch [74/200], Step [4/9], Loss: 2.6930, Accuracy: 97.00%\n",
      "Epoch [74/200], Step [6/9], Loss: 2.6686, Accuracy: 98.00%\n",
      "Epoch [74/200], Step [8/9], Loss: 2.7197, Accuracy: 97.00%\n",
      "Epoch [75/200], Step [2/9], Loss: 2.6743, Accuracy: 98.00%\n",
      "Epoch [75/200], Step [4/9], Loss: 2.7251, Accuracy: 95.00%\n",
      "Epoch [75/200], Step [6/9], Loss: 2.7215, Accuracy: 94.00%\n",
      "Epoch [75/200], Step [8/9], Loss: 2.7151, Accuracy: 98.00%\n",
      "Epoch [76/200], Step [2/9], Loss: 2.6900, Accuracy: 94.00%\n",
      "Epoch [76/200], Step [4/9], Loss: 2.7586, Accuracy: 94.00%\n",
      "Epoch [76/200], Step [6/9], Loss: 2.6945, Accuracy: 95.00%\n",
      "Epoch [76/200], Step [8/9], Loss: 2.6567, Accuracy: 97.00%\n",
      "Epoch [77/200], Step [2/9], Loss: 2.7167, Accuracy: 96.00%\n",
      "Epoch [77/200], Step [4/9], Loss: 2.7163, Accuracy: 98.00%\n",
      "Epoch [77/200], Step [6/9], Loss: 2.6739, Accuracy: 98.00%\n",
      "Epoch [77/200], Step [8/9], Loss: 2.7405, Accuracy: 95.00%\n",
      "Epoch [78/200], Step [2/9], Loss: 2.6554, Accuracy: 99.00%\n",
      "Epoch [78/200], Step [4/9], Loss: 2.6801, Accuracy: 97.00%\n",
      "Epoch [78/200], Step [6/9], Loss: 2.6213, Accuracy: 99.00%\n",
      "Epoch [78/200], Step [8/9], Loss: 2.6738, Accuracy: 98.00%\n",
      "Epoch [79/200], Step [2/9], Loss: 2.7398, Accuracy: 95.00%\n",
      "Epoch [79/200], Step [4/9], Loss: 2.7010, Accuracy: 95.00%\n",
      "Epoch [79/200], Step [6/9], Loss: 2.6778, Accuracy: 98.00%\n",
      "Epoch [79/200], Step [8/9], Loss: 2.6718, Accuracy: 99.00%\n",
      "Epoch [80/200], Step [2/9], Loss: 2.7235, Accuracy: 93.00%\n",
      "Epoch [80/200], Step [4/9], Loss: 2.6849, Accuracy: 96.00%\n",
      "Epoch [80/200], Step [6/9], Loss: 2.6851, Accuracy: 97.00%\n",
      "Epoch [80/200], Step [8/9], Loss: 2.7087, Accuracy: 96.00%\n",
      "Epoch [81/200], Step [2/9], Loss: 2.6831, Accuracy: 96.00%\n",
      "Epoch [81/200], Step [4/9], Loss: 2.6704, Accuracy: 98.00%\n",
      "Epoch [81/200], Step [6/9], Loss: 2.6349, Accuracy: 100.00%\n",
      "Epoch [81/200], Step [8/9], Loss: 2.7004, Accuracy: 94.00%\n",
      "Epoch [82/200], Step [2/9], Loss: 2.6887, Accuracy: 99.00%\n",
      "Epoch [82/200], Step [4/9], Loss: 2.6180, Accuracy: 99.00%\n",
      "Epoch [82/200], Step [6/9], Loss: 2.7568, Accuracy: 93.00%\n",
      "Epoch [82/200], Step [8/9], Loss: 2.7144, Accuracy: 94.00%\n",
      "Epoch [83/200], Step [2/9], Loss: 2.6511, Accuracy: 97.00%\n",
      "Epoch [83/200], Step [4/9], Loss: 2.6365, Accuracy: 99.00%\n",
      "Epoch [83/200], Step [6/9], Loss: 2.6957, Accuracy: 96.00%\n",
      "Epoch [83/200], Step [8/9], Loss: 2.6490, Accuracy: 99.00%\n",
      "Epoch [84/200], Step [2/9], Loss: 2.6397, Accuracy: 97.00%\n",
      "Epoch [84/200], Step [4/9], Loss: 2.6480, Accuracy: 98.00%\n",
      "Epoch [84/200], Step [6/9], Loss: 2.6371, Accuracy: 100.00%\n",
      "Epoch [84/200], Step [8/9], Loss: 2.6849, Accuracy: 100.00%\n",
      "Epoch [85/200], Step [2/9], Loss: 2.6511, Accuracy: 97.00%\n",
      "Epoch [85/200], Step [4/9], Loss: 2.6165, Accuracy: 100.00%\n",
      "Epoch [85/200], Step [6/9], Loss: 2.7347, Accuracy: 89.00%\n",
      "Epoch [85/200], Step [8/9], Loss: 2.6294, Accuracy: 99.00%\n",
      "Epoch [86/200], Step [2/9], Loss: 2.6579, Accuracy: 96.00%\n",
      "Epoch [86/200], Step [4/9], Loss: 2.7339, Accuracy: 96.00%\n",
      "Epoch [86/200], Step [6/9], Loss: 2.6901, Accuracy: 95.00%\n",
      "Epoch [86/200], Step [8/9], Loss: 2.7017, Accuracy: 96.00%\n",
      "Epoch [87/200], Step [2/9], Loss: 2.6098, Accuracy: 99.00%\n",
      "Epoch [87/200], Step [4/9], Loss: 2.6302, Accuracy: 98.00%\n",
      "Epoch [87/200], Step [6/9], Loss: 2.6671, Accuracy: 97.00%\n",
      "Epoch [87/200], Step [8/9], Loss: 2.6340, Accuracy: 99.00%\n",
      "Epoch [88/200], Step [2/9], Loss: 2.6896, Accuracy: 97.00%\n",
      "Epoch [88/200], Step [4/9], Loss: 2.6380, Accuracy: 98.00%\n",
      "Epoch [88/200], Step [6/9], Loss: 2.7163, Accuracy: 96.00%\n",
      "Epoch [88/200], Step [8/9], Loss: 2.6973, Accuracy: 96.00%\n",
      "Epoch [89/200], Step [2/9], Loss: 2.6474, Accuracy: 97.00%\n",
      "Epoch [89/200], Step [4/9], Loss: 2.6773, Accuracy: 95.00%\n",
      "Epoch [89/200], Step [6/9], Loss: 2.6576, Accuracy: 97.00%\n",
      "Epoch [89/200], Step [8/9], Loss: 2.6043, Accuracy: 98.00%\n",
      "Epoch [90/200], Step [2/9], Loss: 2.6542, Accuracy: 97.00%\n",
      "Epoch [90/200], Step [4/9], Loss: 2.6298, Accuracy: 98.00%\n",
      "Epoch [90/200], Step [6/9], Loss: 2.7831, Accuracy: 91.00%\n",
      "Epoch [90/200], Step [8/9], Loss: 2.7132, Accuracy: 98.00%\n",
      "Epoch [91/200], Step [2/9], Loss: 2.6347, Accuracy: 97.00%\n",
      "Epoch [91/200], Step [4/9], Loss: 2.7876, Accuracy: 94.00%\n",
      "Epoch [91/200], Step [6/9], Loss: 2.6614, Accuracy: 96.00%\n",
      "Epoch [91/200], Step [8/9], Loss: 2.6978, Accuracy: 95.00%\n",
      "Epoch [92/200], Step [2/9], Loss: 2.7048, Accuracy: 97.00%\n",
      "Epoch [92/200], Step [4/9], Loss: 2.7298, Accuracy: 96.00%\n",
      "Epoch [92/200], Step [6/9], Loss: 2.7490, Accuracy: 94.00%\n",
      "Epoch [92/200], Step [8/9], Loss: 2.7556, Accuracy: 99.00%\n",
      "Epoch [93/200], Step [2/9], Loss: 2.7912, Accuracy: 93.00%\n",
      "Epoch [93/200], Step [4/9], Loss: 2.6977, Accuracy: 95.00%\n",
      "Epoch [93/200], Step [6/9], Loss: 2.7609, Accuracy: 94.00%\n",
      "Epoch [93/200], Step [8/9], Loss: 2.7090, Accuracy: 94.00%\n",
      "Epoch [94/200], Step [2/9], Loss: 2.6218, Accuracy: 100.00%\n",
      "Epoch [94/200], Step [4/9], Loss: 2.6621, Accuracy: 98.00%\n",
      "Epoch [94/200], Step [6/9], Loss: 2.6852, Accuracy: 97.00%\n",
      "Epoch [94/200], Step [8/9], Loss: 2.6707, Accuracy: 96.00%\n",
      "Epoch [95/200], Step [2/9], Loss: 2.6229, Accuracy: 98.00%\n",
      "Epoch [95/200], Step [4/9], Loss: 2.6381, Accuracy: 98.00%\n",
      "Epoch [95/200], Step [6/9], Loss: 2.6754, Accuracy: 94.00%\n",
      "Epoch [95/200], Step [8/9], Loss: 2.6534, Accuracy: 97.00%\n",
      "Epoch [96/200], Step [2/9], Loss: 2.5935, Accuracy: 100.00%\n",
      "Epoch [96/200], Step [4/9], Loss: 2.6866, Accuracy: 97.00%\n",
      "Epoch [96/200], Step [6/9], Loss: 2.6098, Accuracy: 97.00%\n",
      "Epoch [96/200], Step [8/9], Loss: 2.6272, Accuracy: 97.00%\n",
      "Epoch [97/200], Step [2/9], Loss: 2.6133, Accuracy: 99.00%\n",
      "Epoch [97/200], Step [4/9], Loss: 2.6491, Accuracy: 96.00%\n",
      "Epoch [97/200], Step [6/9], Loss: 2.6344, Accuracy: 97.00%\n",
      "Epoch [97/200], Step [8/9], Loss: 2.6379, Accuracy: 100.00%\n",
      "Epoch [98/200], Step [2/9], Loss: 2.6639, Accuracy: 97.00%\n",
      "Epoch [98/200], Step [4/9], Loss: 2.7257, Accuracy: 93.00%\n",
      "Epoch [98/200], Step [6/9], Loss: 2.6785, Accuracy: 98.00%\n",
      "Epoch [98/200], Step [8/9], Loss: 2.6898, Accuracy: 97.00%\n",
      "Epoch [99/200], Step [2/9], Loss: 2.6671, Accuracy: 97.00%\n",
      "Epoch [99/200], Step [4/9], Loss: 2.6788, Accuracy: 96.00%\n",
      "Epoch [99/200], Step [6/9], Loss: 2.6022, Accuracy: 99.00%\n",
      "Epoch [99/200], Step [8/9], Loss: 2.6398, Accuracy: 99.00%\n",
      "Epoch [100/200], Step [2/9], Loss: 2.5951, Accuracy: 100.00%\n",
      "Epoch [100/200], Step [4/9], Loss: 2.6105, Accuracy: 99.00%\n",
      "Epoch [100/200], Step [6/9], Loss: 2.6736, Accuracy: 96.00%\n",
      "Epoch [100/200], Step [8/9], Loss: 2.6422, Accuracy: 98.00%\n",
      "Epoch [101/200], Step [2/9], Loss: 2.6196, Accuracy: 98.00%\n",
      "Epoch [101/200], Step [4/9], Loss: 2.6452, Accuracy: 98.00%\n",
      "Epoch [101/200], Step [6/9], Loss: 2.6583, Accuracy: 96.00%\n",
      "Epoch [101/200], Step [8/9], Loss: 2.5737, Accuracy: 99.00%\n",
      "Epoch [102/200], Step [2/9], Loss: 2.6297, Accuracy: 98.00%\n",
      "Epoch [102/200], Step [4/9], Loss: 2.6162, Accuracy: 98.00%\n",
      "Epoch [102/200], Step [6/9], Loss: 2.6680, Accuracy: 97.00%\n",
      "Epoch [102/200], Step [8/9], Loss: 2.6256, Accuracy: 98.00%\n",
      "Epoch [103/200], Step [2/9], Loss: 2.6458, Accuracy: 98.00%\n",
      "Epoch [103/200], Step [4/9], Loss: 2.6441, Accuracy: 97.00%\n",
      "Epoch [103/200], Step [6/9], Loss: 2.6557, Accuracy: 96.00%\n",
      "Epoch [103/200], Step [8/9], Loss: 2.6283, Accuracy: 98.00%\n",
      "Epoch [104/200], Step [2/9], Loss: 2.6056, Accuracy: 97.00%\n",
      "Epoch [104/200], Step [4/9], Loss: 2.5931, Accuracy: 100.00%\n",
      "Epoch [104/200], Step [6/9], Loss: 2.6253, Accuracy: 98.00%\n",
      "Epoch [104/200], Step [8/9], Loss: 2.6101, Accuracy: 100.00%\n",
      "Epoch [105/200], Step [2/9], Loss: 2.6766, Accuracy: 96.00%\n",
      "Epoch [105/200], Step [4/9], Loss: 2.6840, Accuracy: 95.00%\n",
      "Epoch [105/200], Step [6/9], Loss: 2.7519, Accuracy: 93.00%\n",
      "Epoch [105/200], Step [8/9], Loss: 2.6864, Accuracy: 96.00%\n",
      "Epoch [106/200], Step [2/9], Loss: 2.6338, Accuracy: 99.00%\n",
      "Epoch [106/200], Step [4/9], Loss: 2.7139, Accuracy: 94.00%\n",
      "Epoch [106/200], Step [6/9], Loss: 2.6280, Accuracy: 98.00%\n",
      "Epoch [106/200], Step [8/9], Loss: 2.7185, Accuracy: 94.00%\n",
      "Epoch [107/200], Step [2/9], Loss: 2.6205, Accuracy: 100.00%\n",
      "Epoch [107/200], Step [4/9], Loss: 2.6722, Accuracy: 97.00%\n",
      "Epoch [107/200], Step [6/9], Loss: 2.7074, Accuracy: 95.00%\n",
      "Epoch [107/200], Step [8/9], Loss: 2.6205, Accuracy: 98.00%\n",
      "Epoch [108/200], Step [2/9], Loss: 2.6480, Accuracy: 95.00%\n",
      "Epoch [108/200], Step [4/9], Loss: 2.6790, Accuracy: 95.00%\n",
      "Epoch [108/200], Step [6/9], Loss: 2.5881, Accuracy: 100.00%\n",
      "Epoch [108/200], Step [8/9], Loss: 2.6583, Accuracy: 95.00%\n",
      "Epoch [109/200], Step [2/9], Loss: 2.6125, Accuracy: 98.00%\n",
      "Epoch [109/200], Step [4/9], Loss: 2.6869, Accuracy: 94.00%\n",
      "Epoch [109/200], Step [6/9], Loss: 2.6219, Accuracy: 98.00%\n",
      "Epoch [109/200], Step [8/9], Loss: 2.6146, Accuracy: 98.00%\n",
      "Epoch [110/200], Step [2/9], Loss: 2.6230, Accuracy: 97.00%\n",
      "Epoch [110/200], Step [4/9], Loss: 2.5799, Accuracy: 97.00%\n",
      "Epoch [110/200], Step [6/9], Loss: 2.5960, Accuracy: 100.00%\n",
      "Epoch [110/200], Step [8/9], Loss: 2.6220, Accuracy: 98.00%\n",
      "Epoch [111/200], Step [2/9], Loss: 2.6068, Accuracy: 99.00%\n",
      "Epoch [111/200], Step [4/9], Loss: 2.5824, Accuracy: 99.00%\n",
      "Epoch [111/200], Step [6/9], Loss: 2.6776, Accuracy: 94.00%\n",
      "Epoch [111/200], Step [8/9], Loss: 2.6625, Accuracy: 97.00%\n",
      "Epoch [112/200], Step [2/9], Loss: 2.6008, Accuracy: 99.00%\n",
      "Epoch [112/200], Step [4/9], Loss: 2.6404, Accuracy: 96.00%\n",
      "Epoch [112/200], Step [6/9], Loss: 2.6687, Accuracy: 97.00%\n",
      "Epoch [112/200], Step [8/9], Loss: 2.6413, Accuracy: 97.00%\n",
      "Epoch [113/200], Step [2/9], Loss: 2.6413, Accuracy: 99.00%\n",
      "Epoch [113/200], Step [4/9], Loss: 2.5455, Accuracy: 98.00%\n",
      "Epoch [113/200], Step [6/9], Loss: 2.5543, Accuracy: 100.00%\n",
      "Epoch [113/200], Step [8/9], Loss: 2.6242, Accuracy: 98.00%\n",
      "Epoch [114/200], Step [2/9], Loss: 2.6676, Accuracy: 93.00%\n",
      "Epoch [114/200], Step [4/9], Loss: 2.5804, Accuracy: 98.00%\n",
      "Epoch [114/200], Step [6/9], Loss: 2.7019, Accuracy: 95.00%\n",
      "Epoch [114/200], Step [8/9], Loss: 2.5784, Accuracy: 100.00%\n",
      "Epoch [115/200], Step [2/9], Loss: 2.6755, Accuracy: 95.00%\n",
      "Epoch [115/200], Step [4/9], Loss: 2.6225, Accuracy: 96.00%\n",
      "Epoch [115/200], Step [6/9], Loss: 2.5915, Accuracy: 97.00%\n",
      "Epoch [115/200], Step [8/9], Loss: 2.6863, Accuracy: 96.00%\n",
      "Epoch [116/200], Step [2/9], Loss: 2.6966, Accuracy: 96.00%\n",
      "Epoch [116/200], Step [4/9], Loss: 2.6430, Accuracy: 98.00%\n",
      "Epoch [116/200], Step [6/9], Loss: 2.6113, Accuracy: 100.00%\n",
      "Epoch [116/200], Step [8/9], Loss: 2.6360, Accuracy: 98.00%\n",
      "Epoch [117/200], Step [2/9], Loss: 2.5765, Accuracy: 99.00%\n",
      "Epoch [117/200], Step [4/9], Loss: 2.6166, Accuracy: 98.00%\n",
      "Epoch [117/200], Step [6/9], Loss: 2.6164, Accuracy: 99.00%\n",
      "Epoch [117/200], Step [8/9], Loss: 2.6014, Accuracy: 98.00%\n",
      "Epoch [118/200], Step [2/9], Loss: 2.5695, Accuracy: 100.00%\n",
      "Epoch [118/200], Step [4/9], Loss: 2.5810, Accuracy: 98.00%\n",
      "Epoch [118/200], Step [6/9], Loss: 2.6303, Accuracy: 96.00%\n",
      "Epoch [118/200], Step [8/9], Loss: 2.6702, Accuracy: 94.00%\n",
      "Epoch [119/200], Step [2/9], Loss: 2.5992, Accuracy: 98.00%\n",
      "Epoch [119/200], Step [4/9], Loss: 2.6040, Accuracy: 98.00%\n",
      "Epoch [119/200], Step [6/9], Loss: 2.6422, Accuracy: 95.00%\n",
      "Epoch [119/200], Step [8/9], Loss: 2.6856, Accuracy: 98.00%\n",
      "Epoch [120/200], Step [2/9], Loss: 2.5748, Accuracy: 99.00%\n",
      "Epoch [120/200], Step [4/9], Loss: 2.6320, Accuracy: 97.00%\n",
      "Epoch [120/200], Step [6/9], Loss: 2.5984, Accuracy: 97.00%\n",
      "Epoch [120/200], Step [8/9], Loss: 2.6512, Accuracy: 97.00%\n",
      "Epoch [121/200], Step [2/9], Loss: 2.6003, Accuracy: 96.00%\n",
      "Epoch [121/200], Step [4/9], Loss: 2.6698, Accuracy: 95.00%\n",
      "Epoch [121/200], Step [6/9], Loss: 2.5869, Accuracy: 100.00%\n",
      "Epoch [121/200], Step [8/9], Loss: 2.6604, Accuracy: 95.00%\n",
      "Epoch [122/200], Step [2/9], Loss: 2.6359, Accuracy: 97.00%\n",
      "Epoch [122/200], Step [4/9], Loss: 2.5806, Accuracy: 100.00%\n",
      "Epoch [122/200], Step [6/9], Loss: 2.5768, Accuracy: 98.00%\n",
      "Epoch [122/200], Step [8/9], Loss: 2.5939, Accuracy: 98.00%\n",
      "Epoch [123/200], Step [2/9], Loss: 2.5648, Accuracy: 98.00%\n",
      "Epoch [123/200], Step [4/9], Loss: 2.5689, Accuracy: 100.00%\n",
      "Epoch [123/200], Step [6/9], Loss: 2.5902, Accuracy: 99.00%\n",
      "Epoch [123/200], Step [8/9], Loss: 2.5746, Accuracy: 99.00%\n",
      "Epoch [124/200], Step [2/9], Loss: 2.6037, Accuracy: 98.00%\n",
      "Epoch [124/200], Step [4/9], Loss: 2.6420, Accuracy: 95.00%\n",
      "Epoch [124/200], Step [6/9], Loss: 2.5963, Accuracy: 98.00%\n",
      "Epoch [124/200], Step [8/9], Loss: 2.5690, Accuracy: 99.00%\n",
      "Epoch [125/200], Step [2/9], Loss: 2.5773, Accuracy: 96.00%\n",
      "Epoch [125/200], Step [4/9], Loss: 2.5829, Accuracy: 95.00%\n",
      "Epoch [125/200], Step [6/9], Loss: 2.6092, Accuracy: 96.00%\n",
      "Epoch [125/200], Step [8/9], Loss: 2.5726, Accuracy: 99.00%\n",
      "Epoch [126/200], Step [2/9], Loss: 2.6361, Accuracy: 97.00%\n",
      "Epoch [126/200], Step [4/9], Loss: 2.6044, Accuracy: 95.00%\n",
      "Epoch [126/200], Step [6/9], Loss: 2.5915, Accuracy: 98.00%\n",
      "Epoch [126/200], Step [8/9], Loss: 2.5833, Accuracy: 97.00%\n",
      "Epoch [127/200], Step [2/9], Loss: 2.5604, Accuracy: 98.00%\n",
      "Epoch [127/200], Step [4/9], Loss: 2.6250, Accuracy: 98.00%\n",
      "Epoch [127/200], Step [6/9], Loss: 2.5964, Accuracy: 98.00%\n",
      "Epoch [127/200], Step [8/9], Loss: 2.5730, Accuracy: 100.00%\n",
      "Epoch [128/200], Step [2/9], Loss: 2.5403, Accuracy: 100.00%\n",
      "Epoch [128/200], Step [4/9], Loss: 2.5677, Accuracy: 97.00%\n",
      "Epoch [128/200], Step [6/9], Loss: 2.6424, Accuracy: 93.00%\n",
      "Epoch [128/200], Step [8/9], Loss: 2.5957, Accuracy: 100.00%\n",
      "Epoch [129/200], Step [2/9], Loss: 2.6062, Accuracy: 96.00%\n",
      "Epoch [129/200], Step [4/9], Loss: 2.5946, Accuracy: 98.00%\n",
      "Epoch [129/200], Step [6/9], Loss: 2.5764, Accuracy: 99.00%\n",
      "Epoch [129/200], Step [8/9], Loss: 2.5757, Accuracy: 98.00%\n",
      "Epoch [130/200], Step [2/9], Loss: 2.6154, Accuracy: 97.00%\n",
      "Epoch [130/200], Step [4/9], Loss: 2.5813, Accuracy: 98.00%\n",
      "Epoch [130/200], Step [6/9], Loss: 2.5822, Accuracy: 98.00%\n",
      "Epoch [130/200], Step [8/9], Loss: 2.6007, Accuracy: 98.00%\n",
      "Epoch [131/200], Step [2/9], Loss: 2.6187, Accuracy: 98.00%\n",
      "Epoch [131/200], Step [4/9], Loss: 2.5716, Accuracy: 99.00%\n",
      "Epoch [131/200], Step [6/9], Loss: 2.5659, Accuracy: 99.00%\n",
      "Epoch [131/200], Step [8/9], Loss: 2.5434, Accuracy: 99.00%\n",
      "Epoch [132/200], Step [2/9], Loss: 2.5710, Accuracy: 98.00%\n",
      "Epoch [132/200], Step [4/9], Loss: 2.5776, Accuracy: 98.00%\n",
      "Epoch [132/200], Step [6/9], Loss: 2.5726, Accuracy: 99.00%\n",
      "Epoch [132/200], Step [8/9], Loss: 2.5900, Accuracy: 99.00%\n",
      "Epoch [133/200], Step [2/9], Loss: 2.5772, Accuracy: 99.00%\n",
      "Epoch [133/200], Step [4/9], Loss: 2.5607, Accuracy: 99.00%\n",
      "Epoch [133/200], Step [6/9], Loss: 2.5252, Accuracy: 99.00%\n",
      "Epoch [133/200], Step [8/9], Loss: 2.6562, Accuracy: 94.00%\n",
      "Epoch [134/200], Step [2/9], Loss: 2.5774, Accuracy: 98.00%\n",
      "Epoch [134/200], Step [4/9], Loss: 2.5262, Accuracy: 100.00%\n",
      "Epoch [134/200], Step [6/9], Loss: 2.6278, Accuracy: 97.00%\n",
      "Epoch [134/200], Step [8/9], Loss: 2.5428, Accuracy: 100.00%\n",
      "Epoch [135/200], Step [2/9], Loss: 2.5719, Accuracy: 100.00%\n",
      "Epoch [135/200], Step [4/9], Loss: 2.6186, Accuracy: 98.00%\n",
      "Epoch [135/200], Step [6/9], Loss: 2.5281, Accuracy: 99.00%\n",
      "Epoch [135/200], Step [8/9], Loss: 2.5668, Accuracy: 99.00%\n",
      "Epoch [136/200], Step [2/9], Loss: 2.5661, Accuracy: 98.00%\n",
      "Epoch [136/200], Step [4/9], Loss: 2.5657, Accuracy: 98.00%\n",
      "Epoch [136/200], Step [6/9], Loss: 2.5396, Accuracy: 100.00%\n",
      "Epoch [136/200], Step [8/9], Loss: 2.6046, Accuracy: 97.00%\n",
      "Epoch [137/200], Step [2/9], Loss: 2.5014, Accuracy: 100.00%\n",
      "Epoch [137/200], Step [4/9], Loss: 2.6253, Accuracy: 94.00%\n",
      "Epoch [137/200], Step [6/9], Loss: 2.6248, Accuracy: 96.00%\n",
      "Epoch [137/200], Step [8/9], Loss: 2.6280, Accuracy: 95.00%\n",
      "Epoch [138/200], Step [2/9], Loss: 2.6131, Accuracy: 97.00%\n",
      "Epoch [138/200], Step [4/9], Loss: 2.5497, Accuracy: 100.00%\n",
      "Epoch [138/200], Step [6/9], Loss: 2.6328, Accuracy: 97.00%\n",
      "Epoch [138/200], Step [8/9], Loss: 2.5949, Accuracy: 98.00%\n",
      "Epoch [139/200], Step [2/9], Loss: 2.5991, Accuracy: 96.00%\n",
      "Epoch [139/200], Step [4/9], Loss: 2.5435, Accuracy: 100.00%\n",
      "Epoch [139/200], Step [6/9], Loss: 2.6337, Accuracy: 94.00%\n",
      "Epoch [139/200], Step [8/9], Loss: 2.5563, Accuracy: 99.00%\n",
      "Epoch [140/200], Step [2/9], Loss: 2.5593, Accuracy: 99.00%\n",
      "Epoch [140/200], Step [4/9], Loss: 2.5844, Accuracy: 99.00%\n",
      "Epoch [140/200], Step [6/9], Loss: 2.5845, Accuracy: 99.00%\n",
      "Epoch [140/200], Step [8/9], Loss: 2.5351, Accuracy: 99.00%\n",
      "Epoch [141/200], Step [2/9], Loss: 2.5839, Accuracy: 95.00%\n",
      "Epoch [141/200], Step [4/9], Loss: 2.5763, Accuracy: 97.00%\n",
      "Epoch [141/200], Step [6/9], Loss: 2.5900, Accuracy: 98.00%\n",
      "Epoch [141/200], Step [8/9], Loss: 2.6274, Accuracy: 96.00%\n",
      "Epoch [142/200], Step [2/9], Loss: 2.5308, Accuracy: 100.00%\n",
      "Epoch [142/200], Step [4/9], Loss: 2.5996, Accuracy: 99.00%\n",
      "Epoch [142/200], Step [6/9], Loss: 2.5619, Accuracy: 97.00%\n",
      "Epoch [142/200], Step [8/9], Loss: 2.5553, Accuracy: 99.00%\n",
      "Epoch [143/200], Step [2/9], Loss: 2.5931, Accuracy: 97.00%\n",
      "Epoch [143/200], Step [4/9], Loss: 2.5870, Accuracy: 97.00%\n",
      "Epoch [143/200], Step [6/9], Loss: 2.5636, Accuracy: 97.00%\n",
      "Epoch [143/200], Step [8/9], Loss: 2.5665, Accuracy: 98.00%\n",
      "Epoch [144/200], Step [2/9], Loss: 2.5853, Accuracy: 98.00%\n",
      "Epoch [144/200], Step [4/9], Loss: 2.5795, Accuracy: 99.00%\n",
      "Epoch [144/200], Step [6/9], Loss: 2.5669, Accuracy: 99.00%\n",
      "Epoch [144/200], Step [8/9], Loss: 2.5524, Accuracy: 99.00%\n",
      "Epoch [145/200], Step [2/9], Loss: 2.6075, Accuracy: 98.00%\n",
      "Epoch [145/200], Step [4/9], Loss: 2.5899, Accuracy: 98.00%\n",
      "Epoch [145/200], Step [6/9], Loss: 2.5689, Accuracy: 100.00%\n",
      "Epoch [145/200], Step [8/9], Loss: 2.5804, Accuracy: 99.00%\n",
      "Epoch [146/200], Step [2/9], Loss: 2.6003, Accuracy: 95.00%\n",
      "Epoch [146/200], Step [4/9], Loss: 2.5827, Accuracy: 96.00%\n",
      "Epoch [146/200], Step [6/9], Loss: 2.5606, Accuracy: 98.00%\n",
      "Epoch [146/200], Step [8/9], Loss: 2.5807, Accuracy: 96.00%\n",
      "Epoch [147/200], Step [2/9], Loss: 2.5445, Accuracy: 100.00%\n",
      "Epoch [147/200], Step [4/9], Loss: 2.5720, Accuracy: 99.00%\n",
      "Epoch [147/200], Step [6/9], Loss: 2.6215, Accuracy: 97.00%\n",
      "Epoch [147/200], Step [8/9], Loss: 2.5427, Accuracy: 97.00%\n",
      "Epoch [148/200], Step [2/9], Loss: 2.5557, Accuracy: 99.00%\n",
      "Epoch [148/200], Step [4/9], Loss: 2.5744, Accuracy: 98.00%\n",
      "Epoch [148/200], Step [6/9], Loss: 2.5871, Accuracy: 98.00%\n",
      "Epoch [148/200], Step [8/9], Loss: 2.5398, Accuracy: 98.00%\n",
      "Epoch [149/200], Step [2/9], Loss: 2.5733, Accuracy: 99.00%\n",
      "Epoch [149/200], Step [4/9], Loss: 2.5473, Accuracy: 99.00%\n",
      "Epoch [149/200], Step [6/9], Loss: 2.5581, Accuracy: 97.00%\n",
      "Epoch [149/200], Step [8/9], Loss: 2.6085, Accuracy: 97.00%\n",
      "Epoch [150/200], Step [2/9], Loss: 2.5535, Accuracy: 98.00%\n",
      "Epoch [150/200], Step [4/9], Loss: 2.6010, Accuracy: 97.00%\n",
      "Epoch [150/200], Step [6/9], Loss: 2.6055, Accuracy: 93.00%\n",
      "Epoch [150/200], Step [8/9], Loss: 2.5656, Accuracy: 98.00%\n",
      "Epoch [151/200], Step [2/9], Loss: 2.5647, Accuracy: 96.00%\n",
      "Epoch [151/200], Step [4/9], Loss: 2.5650, Accuracy: 99.00%\n",
      "Epoch [151/200], Step [6/9], Loss: 2.5546, Accuracy: 99.00%\n",
      "Epoch [151/200], Step [8/9], Loss: 2.6054, Accuracy: 99.00%\n",
      "Epoch [152/200], Step [2/9], Loss: 2.6279, Accuracy: 97.00%\n",
      "Epoch [152/200], Step [4/9], Loss: 2.5846, Accuracy: 99.00%\n",
      "Epoch [152/200], Step [6/9], Loss: 2.5827, Accuracy: 96.00%\n",
      "Epoch [152/200], Step [8/9], Loss: 2.5735, Accuracy: 98.00%\n",
      "Epoch [153/200], Step [2/9], Loss: 2.5564, Accuracy: 99.00%\n",
      "Epoch [153/200], Step [4/9], Loss: 2.5458, Accuracy: 98.00%\n",
      "Epoch [153/200], Step [6/9], Loss: 2.6045, Accuracy: 94.00%\n",
      "Epoch [153/200], Step [8/9], Loss: 2.5564, Accuracy: 96.00%\n",
      "Epoch [154/200], Step [2/9], Loss: 2.5435, Accuracy: 100.00%\n",
      "Epoch [154/200], Step [4/9], Loss: 2.6087, Accuracy: 95.00%\n",
      "Epoch [154/200], Step [6/9], Loss: 2.5909, Accuracy: 97.00%\n",
      "Epoch [154/200], Step [8/9], Loss: 2.5751, Accuracy: 98.00%\n",
      "Epoch [155/200], Step [2/9], Loss: 2.5408, Accuracy: 99.00%\n",
      "Epoch [155/200], Step [4/9], Loss: 2.5488, Accuracy: 99.00%\n",
      "Epoch [155/200], Step [6/9], Loss: 2.6346, Accuracy: 93.00%\n",
      "Epoch [155/200], Step [8/9], Loss: 2.5210, Accuracy: 98.00%\n",
      "Epoch [156/200], Step [2/9], Loss: 2.5478, Accuracy: 99.00%\n",
      "Epoch [156/200], Step [4/9], Loss: 2.5398, Accuracy: 99.00%\n",
      "Epoch [156/200], Step [6/9], Loss: 2.5713, Accuracy: 96.00%\n",
      "Epoch [156/200], Step [8/9], Loss: 2.6048, Accuracy: 98.00%\n",
      "Epoch [157/200], Step [2/9], Loss: 2.5226, Accuracy: 100.00%\n",
      "Epoch [157/200], Step [4/9], Loss: 2.5492, Accuracy: 99.00%\n",
      "Epoch [157/200], Step [6/9], Loss: 2.5935, Accuracy: 97.00%\n",
      "Epoch [157/200], Step [8/9], Loss: 2.5797, Accuracy: 99.00%\n",
      "Epoch [158/200], Step [2/9], Loss: 2.5167, Accuracy: 100.00%\n",
      "Epoch [158/200], Step [4/9], Loss: 2.5364, Accuracy: 99.00%\n",
      "Epoch [158/200], Step [6/9], Loss: 2.5442, Accuracy: 100.00%\n",
      "Epoch [158/200], Step [8/9], Loss: 2.6079, Accuracy: 95.00%\n",
      "Epoch [159/200], Step [2/9], Loss: 2.5513, Accuracy: 98.00%\n",
      "Epoch [159/200], Step [4/9], Loss: 2.5860, Accuracy: 96.00%\n",
      "Epoch [159/200], Step [6/9], Loss: 2.5484, Accuracy: 99.00%\n",
      "Epoch [159/200], Step [8/9], Loss: 2.5689, Accuracy: 99.00%\n",
      "Epoch [160/200], Step [2/9], Loss: 2.5707, Accuracy: 99.00%\n",
      "Epoch [160/200], Step [4/9], Loss: 2.5026, Accuracy: 100.00%\n",
      "Epoch [160/200], Step [6/9], Loss: 2.6052, Accuracy: 95.00%\n",
      "Epoch [160/200], Step [8/9], Loss: 2.5533, Accuracy: 97.00%\n",
      "Epoch [161/200], Step [2/9], Loss: 2.5222, Accuracy: 100.00%\n",
      "Epoch [161/200], Step [4/9], Loss: 2.5480, Accuracy: 99.00%\n",
      "Epoch [161/200], Step [6/9], Loss: 2.5653, Accuracy: 97.00%\n",
      "Epoch [161/200], Step [8/9], Loss: 2.5954, Accuracy: 96.00%\n",
      "Epoch [162/200], Step [2/9], Loss: 2.5956, Accuracy: 97.00%\n",
      "Epoch [162/200], Step [4/9], Loss: 2.5927, Accuracy: 97.00%\n",
      "Epoch [162/200], Step [6/9], Loss: 2.5517, Accuracy: 99.00%\n",
      "Epoch [162/200], Step [8/9], Loss: 2.5917, Accuracy: 96.00%\n",
      "Epoch [163/200], Step [2/9], Loss: 2.6000, Accuracy: 97.00%\n",
      "Epoch [163/200], Step [4/9], Loss: 2.6059, Accuracy: 96.00%\n",
      "Epoch [163/200], Step [6/9], Loss: 2.5893, Accuracy: 96.00%\n",
      "Epoch [163/200], Step [8/9], Loss: 2.5332, Accuracy: 99.00%\n",
      "Epoch [164/200], Step [2/9], Loss: 2.5206, Accuracy: 98.00%\n",
      "Epoch [164/200], Step [4/9], Loss: 2.5512, Accuracy: 99.00%\n",
      "Epoch [164/200], Step [6/9], Loss: 2.6051, Accuracy: 95.00%\n",
      "Epoch [164/200], Step [8/9], Loss: 2.5186, Accuracy: 100.00%\n",
      "Epoch [165/200], Step [2/9], Loss: 2.5508, Accuracy: 98.00%\n",
      "Epoch [165/200], Step [4/9], Loss: 2.5633, Accuracy: 97.00%\n",
      "Epoch [165/200], Step [6/9], Loss: 2.5418, Accuracy: 97.00%\n",
      "Epoch [165/200], Step [8/9], Loss: 2.5140, Accuracy: 99.00%\n",
      "Epoch [166/200], Step [2/9], Loss: 2.5980, Accuracy: 96.00%\n",
      "Epoch [166/200], Step [4/9], Loss: 2.5797, Accuracy: 97.00%\n",
      "Epoch [166/200], Step [6/9], Loss: 2.5548, Accuracy: 98.00%\n",
      "Epoch [166/200], Step [8/9], Loss: 2.5149, Accuracy: 98.00%\n",
      "Epoch [167/200], Step [2/9], Loss: 2.5618, Accuracy: 96.00%\n",
      "Epoch [167/200], Step [4/9], Loss: 2.5457, Accuracy: 99.00%\n",
      "Epoch [167/200], Step [6/9], Loss: 2.5987, Accuracy: 96.00%\n",
      "Epoch [167/200], Step [8/9], Loss: 2.5523, Accuracy: 99.00%\n",
      "Epoch [168/200], Step [2/9], Loss: 2.5799, Accuracy: 99.00%\n",
      "Epoch [168/200], Step [4/9], Loss: 2.5746, Accuracy: 99.00%\n",
      "Epoch [168/200], Step [6/9], Loss: 2.5176, Accuracy: 100.00%\n",
      "Epoch [168/200], Step [8/9], Loss: 2.6097, Accuracy: 96.00%\n",
      "Epoch [169/200], Step [2/9], Loss: 2.5673, Accuracy: 97.00%\n",
      "Epoch [169/200], Step [4/9], Loss: 2.5442, Accuracy: 98.00%\n",
      "Epoch [169/200], Step [6/9], Loss: 2.5182, Accuracy: 99.00%\n",
      "Epoch [169/200], Step [8/9], Loss: 2.5823, Accuracy: 97.00%\n",
      "Epoch [170/200], Step [2/9], Loss: 2.5713, Accuracy: 98.00%\n",
      "Epoch [170/200], Step [4/9], Loss: 2.5825, Accuracy: 98.00%\n",
      "Epoch [170/200], Step [6/9], Loss: 2.5152, Accuracy: 98.00%\n",
      "Epoch [170/200], Step [8/9], Loss: 2.5706, Accuracy: 99.00%\n",
      "Epoch [171/200], Step [2/9], Loss: 2.5486, Accuracy: 97.00%\n",
      "Epoch [171/200], Step [4/9], Loss: 2.5785, Accuracy: 98.00%\n",
      "Epoch [171/200], Step [6/9], Loss: 2.5977, Accuracy: 96.00%\n",
      "Epoch [171/200], Step [8/9], Loss: 2.6156, Accuracy: 97.00%\n",
      "Epoch [172/200], Step [2/9], Loss: 2.5145, Accuracy: 100.00%\n",
      "Epoch [172/200], Step [4/9], Loss: 2.5578, Accuracy: 99.00%\n",
      "Epoch [172/200], Step [6/9], Loss: 2.5428, Accuracy: 100.00%\n",
      "Epoch [172/200], Step [8/9], Loss: 2.5739, Accuracy: 98.00%\n",
      "Epoch [173/200], Step [2/9], Loss: 2.5629, Accuracy: 96.00%\n",
      "Epoch [173/200], Step [4/9], Loss: 2.5620, Accuracy: 99.00%\n",
      "Epoch [173/200], Step [6/9], Loss: 2.5263, Accuracy: 99.00%\n",
      "Epoch [173/200], Step [8/9], Loss: 2.5337, Accuracy: 99.00%\n",
      "Epoch [174/200], Step [2/9], Loss: 2.5419, Accuracy: 98.00%\n",
      "Epoch [174/200], Step [4/9], Loss: 2.5439, Accuracy: 98.00%\n",
      "Epoch [174/200], Step [6/9], Loss: 2.5584, Accuracy: 97.00%\n",
      "Epoch [174/200], Step [8/9], Loss: 2.5363, Accuracy: 98.00%\n",
      "Epoch [175/200], Step [2/9], Loss: 2.5875, Accuracy: 94.00%\n",
      "Epoch [175/200], Step [4/9], Loss: 2.5720, Accuracy: 97.00%\n",
      "Epoch [175/200], Step [6/9], Loss: 2.5475, Accuracy: 97.00%\n",
      "Epoch [175/200], Step [8/9], Loss: 2.5642, Accuracy: 96.00%\n",
      "Epoch [176/200], Step [2/9], Loss: 2.5522, Accuracy: 98.00%\n",
      "Epoch [176/200], Step [4/9], Loss: 2.5119, Accuracy: 100.00%\n",
      "Epoch [176/200], Step [6/9], Loss: 2.4965, Accuracy: 99.00%\n",
      "Epoch [176/200], Step [8/9], Loss: 2.5750, Accuracy: 100.00%\n",
      "Epoch [177/200], Step [2/9], Loss: 2.5321, Accuracy: 99.00%\n",
      "Epoch [177/200], Step [4/9], Loss: 2.4943, Accuracy: 98.00%\n",
      "Epoch [177/200], Step [6/9], Loss: 2.5212, Accuracy: 97.00%\n",
      "Epoch [177/200], Step [8/9], Loss: 2.5197, Accuracy: 99.00%\n",
      "Epoch [178/200], Step [2/9], Loss: 2.5429, Accuracy: 100.00%\n",
      "Epoch [178/200], Step [4/9], Loss: 2.5678, Accuracy: 100.00%\n",
      "Epoch [178/200], Step [6/9], Loss: 2.5445, Accuracy: 99.00%\n",
      "Epoch [178/200], Step [8/9], Loss: 2.5492, Accuracy: 98.00%\n",
      "Epoch [179/200], Step [2/9], Loss: 2.5447, Accuracy: 97.00%\n",
      "Epoch [179/200], Step [4/9], Loss: 2.5356, Accuracy: 99.00%\n",
      "Epoch [179/200], Step [6/9], Loss: 2.5591, Accuracy: 98.00%\n",
      "Epoch [179/200], Step [8/9], Loss: 2.5393, Accuracy: 100.00%\n",
      "Epoch [180/200], Step [2/9], Loss: 2.5492, Accuracy: 98.00%\n",
      "Epoch [180/200], Step [4/9], Loss: 2.5181, Accuracy: 99.00%\n",
      "Epoch [180/200], Step [6/9], Loss: 2.5647, Accuracy: 99.00%\n",
      "Epoch [180/200], Step [8/9], Loss: 2.5354, Accuracy: 100.00%\n",
      "Epoch [181/200], Step [2/9], Loss: 2.5417, Accuracy: 99.00%\n",
      "Epoch [181/200], Step [4/9], Loss: 2.5511, Accuracy: 99.00%\n",
      "Epoch [181/200], Step [6/9], Loss: 2.5129, Accuracy: 99.00%\n",
      "Epoch [181/200], Step [8/9], Loss: 2.5347, Accuracy: 99.00%\n",
      "Epoch [182/200], Step [2/9], Loss: 2.5240, Accuracy: 99.00%\n",
      "Epoch [182/200], Step [4/9], Loss: 2.5444, Accuracy: 99.00%\n",
      "Epoch [182/200], Step [6/9], Loss: 2.5043, Accuracy: 100.00%\n",
      "Epoch [182/200], Step [8/9], Loss: 2.4999, Accuracy: 100.00%\n",
      "Epoch [183/200], Step [2/9], Loss: 2.5631, Accuracy: 98.00%\n",
      "Epoch [183/200], Step [4/9], Loss: 2.4968, Accuracy: 99.00%\n",
      "Epoch [183/200], Step [6/9], Loss: 2.5737, Accuracy: 95.00%\n",
      "Epoch [183/200], Step [8/9], Loss: 2.5257, Accuracy: 99.00%\n",
      "Epoch [184/200], Step [2/9], Loss: 2.5560, Accuracy: 98.00%\n",
      "Epoch [184/200], Step [4/9], Loss: 2.5013, Accuracy: 99.00%\n",
      "Epoch [184/200], Step [6/9], Loss: 2.5560, Accuracy: 98.00%\n",
      "Epoch [184/200], Step [8/9], Loss: 2.6054, Accuracy: 97.00%\n",
      "Epoch [185/200], Step [2/9], Loss: 2.5676, Accuracy: 93.00%\n",
      "Epoch [185/200], Step [4/9], Loss: 2.5043, Accuracy: 99.00%\n",
      "Epoch [185/200], Step [6/9], Loss: 2.5587, Accuracy: 97.00%\n",
      "Epoch [185/200], Step [8/9], Loss: 2.5277, Accuracy: 98.00%\n",
      "Epoch [186/200], Step [2/9], Loss: 2.5219, Accuracy: 98.00%\n",
      "Epoch [186/200], Step [4/9], Loss: 2.5285, Accuracy: 97.00%\n",
      "Epoch [186/200], Step [6/9], Loss: 2.5034, Accuracy: 99.00%\n",
      "Epoch [186/200], Step [8/9], Loss: 2.5251, Accuracy: 99.00%\n",
      "Epoch [187/200], Step [2/9], Loss: 2.4902, Accuracy: 100.00%\n",
      "Epoch [187/200], Step [4/9], Loss: 2.5158, Accuracy: 100.00%\n",
      "Epoch [187/200], Step [6/9], Loss: 2.5529, Accuracy: 97.00%\n",
      "Epoch [187/200], Step [8/9], Loss: 2.5242, Accuracy: 99.00%\n",
      "Epoch [188/200], Step [2/9], Loss: 2.5236, Accuracy: 98.00%\n",
      "Epoch [188/200], Step [4/9], Loss: 2.5181, Accuracy: 98.00%\n",
      "Epoch [188/200], Step [6/9], Loss: 2.5573, Accuracy: 99.00%\n",
      "Epoch [188/200], Step [8/9], Loss: 2.5113, Accuracy: 99.00%\n",
      "Epoch [189/200], Step [2/9], Loss: 2.5287, Accuracy: 98.00%\n",
      "Epoch [189/200], Step [4/9], Loss: 2.5276, Accuracy: 98.00%\n",
      "Epoch [189/200], Step [6/9], Loss: 2.5258, Accuracy: 100.00%\n",
      "Epoch [189/200], Step [8/9], Loss: 2.5746, Accuracy: 97.00%\n",
      "Epoch [190/200], Step [2/9], Loss: 2.5770, Accuracy: 96.00%\n",
      "Epoch [190/200], Step [4/9], Loss: 2.5443, Accuracy: 97.00%\n",
      "Epoch [190/200], Step [6/9], Loss: 2.5127, Accuracy: 99.00%\n",
      "Epoch [190/200], Step [8/9], Loss: 2.5335, Accuracy: 97.00%\n",
      "Epoch [191/200], Step [2/9], Loss: 2.5009, Accuracy: 100.00%\n",
      "Epoch [191/200], Step [4/9], Loss: 2.5189, Accuracy: 99.00%\n",
      "Epoch [191/200], Step [6/9], Loss: 2.5570, Accuracy: 99.00%\n",
      "Epoch [191/200], Step [8/9], Loss: 2.5396, Accuracy: 97.00%\n",
      "Epoch [192/200], Step [2/9], Loss: 2.5471, Accuracy: 98.00%\n",
      "Epoch [192/200], Step [4/9], Loss: 2.5461, Accuracy: 99.00%\n",
      "Epoch [192/200], Step [6/9], Loss: 2.4928, Accuracy: 99.00%\n",
      "Epoch [192/200], Step [8/9], Loss: 2.5187, Accuracy: 97.00%\n",
      "Epoch [193/200], Step [2/9], Loss: 2.5196, Accuracy: 99.00%\n",
      "Epoch [193/200], Step [4/9], Loss: 2.5369, Accuracy: 98.00%\n",
      "Epoch [193/200], Step [6/9], Loss: 2.5255, Accuracy: 99.00%\n",
      "Epoch [193/200], Step [8/9], Loss: 2.6153, Accuracy: 94.00%\n",
      "Epoch [194/200], Step [2/9], Loss: 2.5107, Accuracy: 99.00%\n",
      "Epoch [194/200], Step [4/9], Loss: 2.5248, Accuracy: 98.00%\n",
      "Epoch [194/200], Step [6/9], Loss: 2.5403, Accuracy: 98.00%\n",
      "Epoch [194/200], Step [8/9], Loss: 2.5449, Accuracy: 98.00%\n",
      "Epoch [195/200], Step [2/9], Loss: 2.5533, Accuracy: 99.00%\n",
      "Epoch [195/200], Step [4/9], Loss: 2.5336, Accuracy: 98.00%\n",
      "Epoch [195/200], Step [6/9], Loss: 2.5362, Accuracy: 97.00%\n",
      "Epoch [195/200], Step [8/9], Loss: 2.5289, Accuracy: 99.00%\n",
      "Epoch [196/200], Step [2/9], Loss: 2.4991, Accuracy: 99.00%\n",
      "Epoch [196/200], Step [4/9], Loss: 2.5250, Accuracy: 99.00%\n",
      "Epoch [196/200], Step [6/9], Loss: 2.5058, Accuracy: 100.00%\n",
      "Epoch [196/200], Step [8/9], Loss: 2.5767, Accuracy: 97.00%\n",
      "Epoch [197/200], Step [2/9], Loss: 2.5134, Accuracy: 99.00%\n",
      "Epoch [197/200], Step [4/9], Loss: 2.5125, Accuracy: 99.00%\n",
      "Epoch [197/200], Step [6/9], Loss: 2.5401, Accuracy: 98.00%\n",
      "Epoch [197/200], Step [8/9], Loss: 2.5892, Accuracy: 97.00%\n",
      "Epoch [198/200], Step [2/9], Loss: 2.4810, Accuracy: 99.00%\n",
      "Epoch [198/200], Step [4/9], Loss: 2.5039, Accuracy: 98.00%\n",
      "Epoch [198/200], Step [6/9], Loss: 2.5625, Accuracy: 100.00%\n",
      "Epoch [198/200], Step [8/9], Loss: 2.5132, Accuracy: 99.00%\n",
      "Epoch [199/200], Step [2/9], Loss: 2.5209, Accuracy: 99.00%\n",
      "Epoch [199/200], Step [4/9], Loss: 2.5035, Accuracy: 100.00%\n",
      "Epoch [199/200], Step [6/9], Loss: 2.5409, Accuracy: 96.00%\n",
      "Epoch [199/200], Step [8/9], Loss: 2.5036, Accuracy: 98.00%\n",
      "Epoch [200/200], Step [2/9], Loss: 2.5422, Accuracy: 99.00%\n",
      "Epoch [200/200], Step [4/9], Loss: 2.5429, Accuracy: 98.00%\n",
      "Epoch [200/200], Step [6/9], Loss: 2.5440, Accuracy: 99.00%\n",
      "Epoch [200/200], Step [8/9], Loss: 2.5663, Accuracy: 99.00%\n",
      "Test Accuracy of the model on the test moves: 71.560%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "71.55963302752293"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"load dataframes for the modelling\"\"\"\n",
    "path_file = \"../data/03_processed/padding\"\n",
    "data_dict = data_loader.load_data_dict(path_file)\n",
    "\n",
    "model = model_funcs.Mov1DCNN(num_classes = 20)\n",
    "input_dict = data_dict\n",
    "reg = \"l2\"\n",
    "params = (model , input_dict   , reg )\n",
    "my_testmodel = model_funcs.ModelHandler(*params)\n",
    "\"\"\"train model\"\"\"\n",
    "model_trained =  my_testmodel.train()\n",
    "\"\"\"test model\"\"\"\n",
    "my_testmodel.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3565aeb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(883, 28, 633)\n"
     ]
    }
   ],
   "source": [
    "input_train= np.load(\"../data/03_processed/output_train/input.npy\")\n",
    "print(input_train.shape)\n",
    "out, indices = model_trained(torch.tensor(input_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da365b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([883, 9672])\n"
     ]
    }
   ],
   "source": [
    "# visualization_train,labels_name_train,output_train= my_testmodel.layer_extractor(train=True)\n",
    "reverse_model = gpt_reverse_model.ReverseMov1DCNN(num_classes= 20,maxpool_indices =indices)\n",
    "reconstuct_out = reverse_model(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bfb039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization_train,labels_name_train,output_train= my_testmodel.layer_extractor(train=True)\n",
    "rec_out = reconstuct_out.detach().numpy()\n",
    "np.save(\"../data/03_processed/reconstructed_input.npy\", rec_out)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b9844733",
   "metadata": {},
   "source": [
    "Visualize the reconstructed data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ca501a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "joints = ['ankle1_x', 'knee1_x', 'hip1_x', 'hip2_x', 'knee2_x', 'ankle2_x',\n",
    "       'wrist1_x', 'elbow1_x', 'shoulder1_x', 'shoulder2_x', 'elbow2_x',\n",
    "       'wrist2_x', 'chin_x', 'forehead_x', 'ankle1_y', 'knee1_y', 'hip1_y',\n",
    "       'hip2_y', 'knee2_y', 'ankle2_y', 'wrist1_y', 'elbow1_y', 'shoulder1_y',\n",
    "       'shoulder2_y', 'elbow2_y', 'wrist2_y', 'chin_y', 'forehead_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f1326a1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phone_talking\n",
      "walking\n",
      "pointing\n",
      "phone_talking\n",
      "kicking not calculated\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "movement_name_list = labels_name_train[0:5]\n",
    "\n",
    "pick_traj = 5      # Select a trajectory to simulate\n",
    "fig, ax = plt.subplots(figsize=(8,3))\n",
    "ax.set(xlim=(-1000, 700), ylim=(-700, 700))\n",
    "ax.get_xaxis().set_label_coords(0.5, 0.12)\n",
    "\n",
    "movement_list = [\"walking\", \"jumping_jacks\",\"kicking \",\"phone_talking\",\"pointing\"]\n",
    "        \n",
    "for i,motion in enumerate(movement_name_list):\n",
    "    if motion in movement_list:\n",
    "        camera = Camera(fig)\n",
    "        print(motion)\n",
    "        data = rec_out[i]\n",
    "        df = pd.DataFrame(data).transpose()\n",
    "                \n",
    "        df.columns = joints\n",
    "        for t in range(df.shape[0]):\n",
    "\n",
    "                    # Projectile's trajectory\n",
    "            x = {}\n",
    "            y = {}\n",
    "            for j in range(int(len(joints)/2)):\n",
    "                    x[joints[j]] = df[joints[j]].to_numpy()\n",
    "                    y[joints[j+14]] = df[joints[j+14]].to_numpy()\n",
    "                            # Show Projectile's location\n",
    "                    ax.plot(x[joints[j]][t], y[joints[j+14]][t], marker='o', markersize=4, markeredgecolor='r', markerfacecolor='r')\n",
    "\n",
    "\n",
    "                    # Show Projectile's trajectory\n",
    "            ax.plot([x[\"shoulder1_x\"][t],x[\"chin_x\"][t], x[\"shoulder2_x\"][t]],[y[\"shoulder1_y\"][t], y[\"chin_y\"][t],y[\"shoulder2_y\"][t]],'ro-')\n",
    "            ax.plot([x[\"shoulder1_x\"][t],x[\"elbow1_x\"][t], x[\"wrist1_x\"][t]],[y[\"shoulder1_y\"][t], y[\"elbow1_y\"][t],y[\"wrist1_y\"][t]],'ro-')\n",
    "            ax.plot([x[\"shoulder2_x\"][t],x[\"elbow2_x\"][t], x[\"wrist2_x\"][t]],[y[\"shoulder2_y\"][t], y[\"elbow2_y\"][t],y[\"wrist2_y\"][t]],'ro-')\n",
    "            ax.plot([x[\"shoulder1_x\"][t],x[\"hip1_x\"][t], x[\"hip2_x\"][t], x[\"shoulder2_x\"][t]],[y[\"shoulder1_y\"][t], y[\"hip1_y\"][t],y[\"hip2_y\"][t],\n",
    "            y[\"shoulder2_y\"][t]],'ro-')\n",
    "            ax.plot([x[\"hip1_x\"][t],x[\"knee1_x\"][t], x[\"ankle1_x\"][t]],[y[\"hip1_y\"][t],y[\"knee1_y\"][t], y[\"ankle1_y\"][t]],'ro-')\n",
    "            ax.plot([x[\"hip2_x\"][t],x[\"knee2_x\"][t], x[\"ankle2_x\"][t]],[y[\"hip2_y\"][t],y[\"knee2_y\"][t], y[\"ankle2_y\"][t]],'ro-')\n",
    "            ax.plot([x[\"forehead_x\"][t],x[\"chin_x\"][t]],[y[\"forehead_y\"][t],y[\"chin_y\"][t]],'ro-') \n",
    "            \n",
    "                    # Capture frame\n",
    "            camera.snap()\n",
    "        anim = camera.animate(interval = 30, repeat = False)\n",
    "                # if motion == \"throw/catch\":\n",
    "                #     motion = \"throw&catch\"\n",
    "        anim.save('../reports/reconstructed_output/{}_{}.mp4'.format(motion,i))\n",
    "    else:\n",
    "        print(motion, \"not calculated\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9212e4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(436, 28, 633)\n",
      "(1319, 20)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 2-dimensional, but 3 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m my_testmodel \u001b[39m=\u001b[39m model_funcs\u001b[39m.\u001b[39mModelHandler(\u001b[39m*\u001b[39mparams)\n\u001b[1;32m     36\u001b[0m \u001b[39m# \"\"\"train model\"\"\"\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m my_testmodel\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/My Project/notebooks/../movement_classifier/model_funcs.py:153\u001b[0m, in \u001b[0;36mModelHandler.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_epochs):\n\u001b[1;32m    152\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreal_train_labels \u001b[39m=\u001b[39m[]\n\u001b[0;32m--> 153\u001b[0m     \u001b[39mfor\u001b[39;00m i, (motions, labels) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_loader):\n\u001b[1;32m    154\u001b[0m         motions, labels \u001b[39m=\u001b[39m motions\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice), labels\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    156\u001b[0m         \u001b[39m# print(\"motions\",motions.shape)\u001b[39;00m\n\u001b[1;32m    157\u001b[0m         \u001b[39m# Run the forward pass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    520\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> 521\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    522\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    523\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    524\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    525\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    560\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    562\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    563\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/My Project/notebooks/../movement_classifier/model_funcs.py:111\u001b[0m, in \u001b[0;36mMotionDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mis_tensor(idx):\n\u001b[1;32m    110\u001b[0m     idx \u001b[39m=\u001b[39m idx\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m--> 111\u001b[0m sample \u001b[39m=\u001b[39m (np\u001b[39m.\u001b[39mfloat32(np\u001b[39m.\u001b[39msqueeze(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_array[idx,:,:])), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels[idx])\n\u001b[1;32m    112\u001b[0m \u001b[39mreturn\u001b[39;00m sample\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 2-dimensional, but 3 were indexed"
     ]
    }
   ],
   "source": [
    "# run model on reconstructed input\n",
    "reconstrcuted_input= np.load(\"../data/03_processed/reconstructed_input.npy\")\n",
    "labels_name_train = np.load(\"../data/03_processed/output_train/labels_name.npy\")\n",
    "labels_train = np.load(\"../data/03_processed/output_train/labels.npy\")\n",
    "\n",
    "\n",
    "input_dict = {}\n",
    "input_dict[\"input_model\"] = reconstrcuted_input\n",
    "input_dict[\"labels_name\"] = labels_name_train\n",
    "input_dict[\"labels\"] = labels_train\n",
    "\n",
    "# model = model_funcs.Mov1DCNN(num_classes = 20)\n",
    "# reg = \"l2\"\n",
    "# params = (model , input_dict   , reg )\n",
    "# my_testmodel = model_funcs.ModelHandler(*params)\n",
    "# \"\"\"train model\"\"\"\n",
    "# model_trained =  my_testmodel.train()\n",
    "\"\"\"test model\"\"\"\n",
    "my_testmodel.test()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2f4139ea02f94d37a6f7fb6a86343f3889edf31c93d195ac0fec48efca8f94e4"
  },
  "jupytext": {
   "formats": "ipynb,jupytext//py"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
